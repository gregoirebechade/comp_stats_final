{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [str(i) for i in range(31)]\n",
    "counts = ['0' + i if len(i) == 1 else i for i in counts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque eeg = 19 x 31 000\n",
    "On va les découper en patchs de 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 31000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./../data/kaggle_2/s00.csv', header=None).transpose().to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            # Précharger tous les fichiers en mémoire pour accélérer l'accès\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file**2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // self.n_samples_per_file**2\n",
    "        sample = (idx % self.n_samples_per_file)\n",
    "        first = (sample % (31*4))*250\n",
    "        second = (sample // (31%4))*250\n",
    "        if first + self.segment_length > len(self.data[file][0]):\n",
    "            first = len(self.data[file][0]) - self.segment_length\n",
    "        if second + self.segment_length > len(self.data[file][0]):\n",
    "            second = len(self.data[file][0]) - self.segment_length\n",
    "       \n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        # print(x1.shape)\n",
    "        # print(x2.shape)\n",
    "        # print(first, second)\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15376"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((31*4)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "tensor([[20750,  6750]])\n"
     ]
    }
   ],
   "source": [
    "# dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "# dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "# dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)\n",
    "\n",
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1])\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "        record_number = int(self.X[idx].split('_')[0])\n",
    "        return torch.tensor(x), torch.tensor(labels[record_number]) # un eeg sur 1000 échantillonages et le label correspondant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m l\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39my_pred\u001b[38;5;241m*\u001b[39mlabel_predicted))\n\u001b[0;32m     47\u001b[0m counttrain\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 48\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m losstrain\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39ml\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_extractor = True\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print(epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_classes = 2):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classifier = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
