{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n",
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.fc(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8095238095238095\n",
      "F1 score not pretrained 0.7686658506731946\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_test:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    # print(batch_x.shape)\n",
    "    # print(batch_y)\n",
    "    \n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    # print(batch_y.numpy())\n",
    "    # print(y_true)\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    # print(y_true)\n",
    "    # print(y_pretrained.flatten())\n",
    "    # print(y_not_pretrained)\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision pretrained 0.68\n",
      "precision not pretrained 0.6826086956521739\n"
     ]
    }
   ],
   "source": [
    "print('precision pretrained', precision_score(y_true, y_pred_pretrained))\n",
    "print('precision not pretrained', precision_score(y_true, y_pred_not_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall pretrained 1.0\n",
      "recall not pretrained 0.8795518207282913\n"
     ]
    }
   ],
   "source": [
    "print('recall pretrained', recall_score(y_true, y_pred_pretrained))\n",
    "print('recall not pretrained', recall_score(y_true, y_pred_not_pretrained))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
