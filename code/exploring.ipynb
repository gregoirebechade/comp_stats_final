{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n",
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.fc(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2209e+15],\n",
      "        [1.5436e+15],\n",
      "        [1.2120e+15],\n",
      "        [1.3875e+15],\n",
      "        [1.9200e+15]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pred = model(batch_x.float())\n",
    "    print(y_pred)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8117782909930715\n",
      "F1 score not pretrained 0.7786732796032237\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_val:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot( np.arange(0, 1, 0.02),les_pretrained,  label='pretrained')\n",
    "plt.plot( np.arange(0, 1, 0.02),   les_not_pretrained,   label='not pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/extractor.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
