{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n"
     ]
    }
   ],
   "source": [
    "# dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m :\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m :\n\u001b[0;32m      2\u001b[0m   x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from train_classifiers import EEGClassifier\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self, feature_extractor):\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "#         self.feature_extractor = feature_extractor\n",
    "#         self.fc = nn.Linear(100, 1)\n",
    "#         self.f = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.feature_extractor(x)\n",
    "#         features = F.normalize(features, p=2, dim=1)\n",
    "#         x = self.fc(features)\n",
    "#         return nn.Sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m losstrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m counttrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x,batch_y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m:\n\u001b[0;32m     16\u001b[0m     batch_x\u001b[38;5;241m=\u001b[39mbatch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "model_not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pred = model(batch_x.float())\n",
    "    print(y_pred)\n",
    "    # print(model_not_pretrained(batch_x.float()))\n",
    "    print(batch_y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8117782909930715\n",
      "F1 score not pretrained 0.8117782909930715\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_val:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(-3, 3, 0.02):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot( np.arange(-3, 3, 0.02),les_pretrained,  label='pretrained')\n",
    "plt.plot( np.arange(-3, 3, 0.02),   les_not_pretrained,   label='not pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8621],\n",
      "        [0.5309],\n",
      "        [0.8731],\n",
      "        [0.8524],\n",
      "        [0.6546]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_not_pretrained_final.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7381],\n",
      "        [0.7025],\n",
      "        [0.7339],\n",
      "        [0.7447],\n",
      "        [0.7194]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
