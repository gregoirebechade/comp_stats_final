{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "# dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m :\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m :\n\u001b[0;32m      2\u001b[0m   x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from train_classifiers import EEGClassifier\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self, feature_extractor):\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "#         self.feature_extractor = feature_extractor\n",
    "#         self.fc = nn.Linear(100, 1)\n",
    "#         self.f = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.feature_extractor(x)\n",
    "#         features = F.normalize(features, p=2, dim=1)\n",
    "#         x = self.fc(features)\n",
    "#         return nn.Sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m losstrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m counttrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x,batch_y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m:\n\u001b[0;32m     16\u001b[0m     batch_x\u001b[38;5;241m=\u001b[39mbatch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m     batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0018],\n",
      "        [0.9995],\n",
      "        [0.9987],\n",
      "        [1.0003],\n",
      "        [0.9997]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0., 1., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "model_not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pred = model(batch_x.float())\n",
    "    print(y_pred)\n",
    "    # print(model_not_pretrained(batch_x.float()))\n",
    "    print(batch_y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8117782909930715\n",
      "F1 score not pretrained 0.7824497257769651\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_val:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(-3, 3, 0.01):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot( np.arange(-3, 3, 0.01),les_pretrained,  label='pretrained')\n",
    "plt.plot( np.arange(-3, 3, 0.01),   les_not_pretrained,   label='not pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9974],\n",
      "        [1.0001],\n",
      "        [0.9990],\n",
      "        [1.0015],\n",
      "        [0.9969]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_not_pretrained_final.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9982],\n",
      "        [1.0004],\n",
      "        [0.9993],\n",
      "        [0.9990],\n",
      "        [0.9968]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0, 1, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    print(batch_y)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
