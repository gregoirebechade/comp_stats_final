{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n",
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from train_classifiers import EEGClassifier\n",
    "# class EEGClassifier(nn.Module):\n",
    "#     def __init__(self, feature_extractor):\n",
    "#         super(EEGClassifier, self).__init__()\n",
    "#         self.feature_extractor = feature_extractor\n",
    "#         self.fc = nn.Linear(100, 1)\n",
    "#         self.f = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.feature_extractor(x)\n",
    "#         features = F.normalize(features, p=2, dim=1)\n",
    "#         x = self.fc(features)\n",
    "#         return self.f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7470],\n",
      "        [0.7194],\n",
      "        [0.7828],\n",
      "        [0.7669],\n",
      "        [0.7663]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([1., 1., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "model_not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pred = model(batch_x.float())\n",
    "    print(y_pred)\n",
    "    # print(model_not_pretrained(batch_x.float()))\n",
    "    print(batch_y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8117782909930715\n",
      "F1 score not pretrained 0.7827145465611687\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_val:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(-3, 3, 0.02):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot( np.arange(-3, 3, 0.02),les_pretrained,  label='pretrained')\n",
    "plt.plot( np.arange(-3, 3, 0.02),   les_not_pretrained,   label='not pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8621],\n",
      "        [0.5309],\n",
      "        [0.8731],\n",
      "        [0.8524],\n",
      "        [0.6546]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_not_pretrained_final.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7381],\n",
      "        [0.7025],\n",
      "        [0.7339],\n",
      "        [0.7447],\n",
      "        [0.7194]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
