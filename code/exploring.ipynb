{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n",
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.fc(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.5017064846416381\n",
      "F1 score not pretrained 0.7631901840490798\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final_bis.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_test:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 9.1155e+14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.1955e+14, 0.0000e+00, 0.0000e+00, 3.0805e+14, 1.5896e+15,\n",
      "        0.0000e+00, 0.0000e+00, 4.5065e+14, 5.1553e+14, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.7604e+14, 3.9029e+14, 0.0000e+00, 4.3547e+14,\n",
      "        0.0000e+00, 6.6053e+14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9945e+14, 0.0000e+00,\n",
      "        3.6748e+14, 0.0000e+00, 5.8330e+14, 5.2014e+14, 0.0000e+00, 0.0000e+00,\n",
      "        1.2662e+14, 0.0000e+00, 1.3819e+14, 3.6896e+14, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.1074e+14, 0.0000e+00, 1.7009e+13, 5.9051e+14, 3.7580e+14,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8925e+14, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3225e+14, 7.7732e+14, 7.6063e+14,\n",
      "        0.0000e+00, 0.0000e+00, 2.1837e+14, 2.1970e+14, 5.6417e+14, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 8.4694e+14, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3976e+14, 1.1054e+14, 0.0000e+00,\n",
      "        4.7270e+14, 4.6171e+14, 8.5452e+14, 0.0000e+00, 0.0000e+00, 2.5245e+14,\n",
      "        5.4537e+14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.3017e+14, 4.2805e+14, 0.0000e+00],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/extractor_final.pth')\n",
    "for batch_x , batch_y in dataloader_train:\n",
    "    print(model(batch_x.float())[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = torch.load('./models/extractor_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_y in dataloader_test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA90lEQVR4nO3de3hU9b32/3syk5kcIBMkEkBCSAUBSbEQKgRFPEaxtbXt3rLFh0MLKgJiTLEbpFWhXs2uImCtQdmCiFo3Twv686l4SFs5WEAlDbXdoGBFk8JgDJUECWSSyfr9MZkhQ45rmMyJ9+u65pJZrDXzybhI7nyPFsMwDAEAAERIQqQLAAAA5zbCCAAAiCjCCAAAiCjCCAAAiCjCCAAAiCjCCAAAiCjCCAAAiCjCCAAAiChbpAvoiqamJh0+fFg9e/aUxWKJdDkAAKALDMPQ8ePH1b9/fyUktN/+ERNh5PDhw8rKyop0GQAAIAiVlZUaMGBAu38fE2GkZ8+ekrxfTFpaWoSrAQAAXVFbW6usrCz/z/H2xEQY8XXNpKWlEUYAAIgxnQ2xYAArAACIKMIIAACIKMIIAACIqJgYMwIACB3DMNTY2CiPxxPpUhDjrFarbDbbWS+7QRgBgHOI2+2Wy+VSXV1dpEtBnEhJSVG/fv1kt9uDfg3CCACcI5qamnTw4EFZrVb1799fdrudhSQRNMMw5Ha79cUXX+jgwYMaMmRIhwubdYQwAgDnCLfbraamJmVlZSklJSXS5SAOJCcnKzExUZ999pncbreSkpKCeh0GsALAOSbY316BtoTifuKOBAAAEUUYAQAgRCwWi1555ZVuf59BgwZp5cqV3f4+4UIYAQCcs0L9Q93lcmnSpEkhe71zBWEEABB33G53yF7L4/GoqampS+f27dtXDocjZO99rjinZ9O8/8qT8hzeE+kyzikWew8N/7fFSkvPiHQpAGLIlVdeqdzcXEnSCy+8IKvVqrvuuks///nPZbFYNGjQIM2aNUsff/yxXn75Zd1888167rnntGPHDi1cuFDvv/++MjIy9L3vfU/FxcVKTU3VlVdeqc8++0z33nuv7r33Xkne6arr1q1TYWGhXnjhBf3kJz/R/v37deDAAVVXV+v+++9XeXm5Ghoa9I1vfEMrVqzQ6NGj/XVaLBb/+3/66afKycnRxo0b9cQTT+jdd9/VkCFD9NRTTyk/P99/TUc1SlJVVZVmzpypP/zhD+rbt68efvjhMH7y4RFUGCkpKdGjjz4ql8ulESNGaOXKlZowYUK757/44ot65JFHdODAATmdTt1www1atmyZevfuHXThoWD5xx817vgfI1rDuWjf775S2qz/jnQZAOT94XuyIfwrsSYnWk2vcfLcc89p5syZevfdd7V7927dcccdys7O1u233y5JevTRR/Wzn/1MP/3pTyVJf/vb33T99dfr5z//udasWaMvvvhC8+bN07x58/Tss89q06ZNuuSSS3THHXf4X8Onrq5OxcXFeuaZZ9S7d2/16dNHBw8e1PTp0/WrX/1KkvTYY4/pxhtv1IEDB9SzZ8926168eLGWLVumIUOGaPHixbr11lv18ccfy2azdVqjJM2YMUOVlZX605/+JLvdrvnz56uqqsrUZxftTIeRDRs2qLCwUCUlJbrsssv09NNPa9KkSdq7d68GDhzY6vx33nlH06ZN04oVK3TTTTfp0KFDmj17tmbNmqWXX345JF9EsCzDbtTOw1kRreFc8uXRL3Tjqdc05NAr0vGHpZ6ZkS4JOOedbPDo4gfeDPv77l16vVLs5n4EZWVlacWKFbJYLBo6dKj+9re/acWKFf4gcfXVV2vBggX+86dNm6YpU6aosLBQkjRkyBD96le/0sSJE7Vq1Sqdd955slqt6tmzp/r27RvwXg0NDSopKdEll1ziP3b11VcHnPP000+rV69e2rp1q7797W+3W/eCBQv0rW99S5K0ZMkSjRgxQh9//LGGDRumRx99tMMaKyoq9Prrr2vXrl0aO3asJGnNmjUaPny4qc8u2pkOI8uXL9fMmTM1a9YsSdLKlSv15ptvatWqVSouLm51/q5duzRo0CDNnz9fkpSTk6M777xTjzzyyFmWfvbyvjUr0iWcU371h/36y7aPNDrhY2nnr6WCn0e6JAAxZNy4cQGtKfn5+Xrsscf8e+yMGTMm4PyysjJ9/PHHevHFF/3HDMPwr0Tb0Q90u92ukSNHBhyrqqrSAw88oD/96U/6/PPP5fF4VFdXp4qKig7rbvk6/fr187/WsGHDOq1x//79stlsAV/bsGHDlJ6e3uF7xhpTYcTtdqusrEwLFy4MOF5QUKAdO3a0ec348eO1ePFibd68WZMmTVJVVZV+97vf+VNiW+rr61VfX+9/Xltba6ZMRKleqXb9uvFmrbUvk3avlS6/V0o5L9JlAee05ESr9i69PiLvG2q+MRY+TU1NuvPOO/2/DLfUVkt+S8nJya26kWbMmKEvvvhCK1euVHZ2thwOh/Lz8zsdLJuYmOj/s+81fQNiO6vxo48+CrguXpkKI9XV1fJ4PMrMDGxez8zM1JEjR9q8Zvz48XrxxRc1efJknTp1So2NjfrOd76jJ554ot33KS4u1pIlS8yUhhjgTLHrT02j9JktR9nug9J7q6UrF3Z+IYBuY7FYTHeXRMquXbtaPR8yZIis1raDzejRo/W///u/Gjx4cLuvabfbu7x78fbt21VSUqIbb7xRklRZWanq6uouVt+2zmocPny4GhsbtXv3bl166aWSpI8++kjHjh07q/eNNkFN7T0zoRmG0W5q27t3r+bPn68HHnhAZWVleuONN3Tw4EHNnj273ddftGiRampq/I/KyspgykSU6ZWSKMmiF+3/7j2wa5VUfzyiNQGIHZWVlSoqKtJHH32kl156SU888YTuueeeds//z//8T+3cuVNz587Vnj17dODAAb366qu6++67/ecMGjRI27Zt06FDhzoNFoMHD9bzzz+vffv26d1339Vtt92m5OTks/qaOqtx6NChuuGGG3T77bfr3XffVVlZmWbNmnXW7xttTIWRjIwMWa3WVq0gVVVVrVpLfIqLi3XZZZfpvvvu08iRI3X99derpKREa9eulcvlavMah8OhtLS0gAdiX3qyd3vp3zd8UzrvQunUMalsXURrAhA7pk2bppMnT+rSSy/V3Llzdffdd+uOO+5o9/yRI0dq69atOnDggCZMmKBRo0bpZz/7mX/chiQtXbpUn376qS688EKdf/75Hb7/2rVr9eWXX2rUqFGaOnWq5s+frz59+pzV19SVGp999lllZWVp4sSJ+v73v6877rjjrN832lgMwzDMXDB27Fjl5eWppKTEf+ziiy/Wd7/73TYHsP7gBz+QzWbThg0b/Md27typ8ePH69ChQ+rfv3+n71lbWyun06mamhqCSQyr/FedJjzythy2BH30/Wrp1XlSj0zpng+kxOB2egTQdadOndLBgweVk5MT9O6qkXLllVfqG9/4RlwtgR4vOrqvuvrz23Q3TVFRkZ555hmtXbtW+/bt07333quKigp/t8uiRYs0bdo0//k33XSTNm3apFWrVumTTz7Rn//8Z82fP1+XXnppl4II4kd6incQV31jk05d/G9S2gDpq8+lPS92ciUAIJ6ZHrU0efJkHT16VEuXLpXL5VJubq42b96s7OxsSd51+VtOc5oxY4aOHz+uX//61/rxj3+s9PR0XX311frlL38Zuq8CMaGHwyZbgkWNTYaO1VvU97L50us/kf68Uho9TbImdvoaAID4Y7qbJhLopokfYx4uVfVXbr1+zwQN722TVn5dqquWvve0dMl/RLo8IK7FcjcNoldEummAs+FM9rZ+HKtrkOwpUv5c719sXy51cSMqAEB8IYwgrHqleGfUHKtrXiTomzMlh1Oq/kj68PcRrAwAECmEEYSVbxDrsZMN3gNJTmls89S87cuk6O81BACEGGEEYZXe3DLyZV2L5ZPH3iUlpkiuv0r/YBdlADjXEEYQVunNY0Zq6hpOH0ztLeX90PvnbY9FoCoAQCQRRhBWvVLbaBmRpPHzpIREqWKH9Fnbmy4CAOITYQRhFTCbpqW0/tI3pnj/vJ3WEQDozKBBg8KyIu2VV16pwsLCbn2P2NiqEXGj1QDWli4vlMqflz7+g/T+M1JK7/AWB5wtR08p50rJyrfWaPPQQw/plVde0Z49eyJWQ6iXtH///feVmpoakteKNP7FIKxaTe1t6byvSbk/kP72W+m1H4e5MiBEvr1CGvOjSFeBMHK73bLb7SF5LcMw5PF4ZLN1/uO5s439YglhBGHVbjeNzzUPSvVfSfXHw1gVEAL/+kQ6flg6VhnpSuLOlVdeqZEjRyopKUnPPPOM7Ha7Zs+erYceesh/TkVFhe6++2798Y9/VEJCgm644QY98cQTyszM1Lp167RkyRJJksVikeTdCXfGjBmt3mvGjBk6duyYRo0apSeffFKnTp3SrbfeqieeeMIfOK688krl5ubKbrdr/fr1GjFihLZu3aq9e/dqwYIF2rZtm1JTU1VQUKAVK1YoIyNDM2bM0NatW7V161Y9/vjjkqSDBw/q008/1VVXXaU33nhDixcv1gcffKA333xTAwcOVFFRkXbt2qUTJ05o+PDhKi4u1rXXXuuvddCgQSosLPR3oVgsFv33f/+3XnvtNb355pu64IIL9Nhjj+k73/mO/5qOapSkEydO6K677tKmTZvUs2dPLViwIGT/HztkxICamhpDklFTUxPpUnCW/vllnZH9n783hty/2Whqaop0OUDovPWAYTyYZhhv3B/pStp18uRJY+/evcbJkydPH2xqMoz6r8L/MPHvf+LEiUZaWprx0EMPGfv37zeee+45w2KxGG+99Vbzl9BkjBo1yrj88suN3bt3G7t27TJGjx5tTJw40TAMw6irqzN+/OMfGyNGjDBcLpfhcrmMurq6Nt9r+vTpRo8ePYzJkycbf//7343f//73xvnnn2/cf//p/68TJ040evToYdx3333Ghx9+aOzbt884fPiwkZGRYSxatMjYt2+f8Ze//MW47rrrjKuuusowDMM4duyYkZ+fb9x+++3+GhobG423337bkGSMHDnSeOutt4yPP/7YqK6uNvbs2WM89dRTxgcffGDs37/fWLx4sZGUlGR89tln/jqys7ONFStW+J9LMgYMGGD85je/MQ4cOGDMnz/f6NGjh3H06FHDMIxOazQMw7jrrruMAQMGGG+99ZbxwQcfGN/+9reNHj16GPfcc0+7/3/avK+adfXnNy0jCCvf1F63p0knGzxKsXMLIk7YHN7/Np6KbB1mNdRJv4jADur3H5bsXR/vMHLkSD344IOSpCFDhujXv/61/vjHP+q6667TH/7wB33wwQc6ePCgsrKyJEnPP/+8RowYoffff1/f/OY31aNHD9lsNvXt27fT97Lb7Vq7dq1SUlI0YsQILV26VPfdd59+/vOfKyHBO+9j8ODBeuSRR/zXPPDAAxo9erR+8Ytf+I+tXbtWWVlZ2r9/vy666CLZ7XalpKS0WcPSpUt13XXX+Z/37t1bl1xyif/5ww8/rJdfflmvvvqq5s2b127tM2bM0K233ipJ+sUvfqEnnnhC7733nm644QatWrWqwxr79++vNWvWaP369f5annvuOQ0YMKDTz+xs8ZMAYZVit8puTZDb06Qv6xoII4gf/jBSH9k64tTIkSMDnvfr109VVVWSpH379ikrK8sfRCTp4osvVnp6uvbt26dvfvObpt7rkksuUUpKiv95fn6+vvrqK1VWVvp3qB8zZkzANWVlZXr77bfVo0ePVq/3j3/8QxdddFGH73nm6504cUJLlizR73//ex0+fFiNjY06efKkKioqOnydlp9Tamqqevbs6f+cOqvx5MmTcrvdys/P9x8/77zzNHTo0A7fMxT4SYCwslgscqYk6ovj9TpW59YF6cmRLgkIDWuMhpHEFG8rRSTe18zpiYkBzy0Wi5qaN9c0DMM/FqSl9o4Hq+VrnTmLpampSTfddJN++ctftrquX79+nb72ma9333336c0339SyZcs0ePBgJScn69/+7d/kdrcx+L+Fjj6nzmo8cOBAp3V2F8IIwi492RtGatobxArEIl/LiCfGwojFYqq7JBpdfPHFqqioUGVlpb91ZO/evaqpqdHw4cMlebtePB5Pl17vr3/9q06ePKnkZO8vS7t27VKPHj067K4YPXq0Nm7cqEGDBrU7E8ZMDdu3b9eMGTP0ve99T5L01Vdf6dNPP+3StcHWOHjwYCUmJmrXrl0aOHCgJOnLL7/U/v37NXHixLN6786w6BnCrpd/fxrCCOKIv5um499cEXrXXnutRo4cqdtuu01/+ctf9N5772natGmaOHGiv/tj0KBBOnjwoPbs2aPq6mrV17cfGt1ut2bOnKm9e/fq9ddf14MPPqh58+b5x4u0Ze7cufrXv/6lW2+9Ve+9954++eQTvfXWW/rRj37kDyCDBg3Su+++q08//VTV1dX+Fou2DB48WJs2bdKePXv017/+VVOmTOnw/K7orMYePXpo5syZuu+++/THP/5Rf//73zVjxowOv+5QIYwg7Jz+hc/4po04Yo3RAaxxwGKx6JVXXlGvXr10xRVX6Nprr9XXvvY1bdiwwX/OD37wA91www266qqrdP755+ull15q9/WuueYaDRkyRFdccYVuueUW3XTTTQHTiNvSv39//fnPf5bH49H111+v3Nxc3XPPPXI6nf4f5gsWLJDVatXFF1+s888/v8PxHytWrFCvXr00fvx43XTTTbr++us1evRocx9MEDU++uijuuKKK/Sd73xH1157rS6//HLl5eWd1ft2haV5OlBUq62tldPpVE1NjdLS0iJdDs7ST373V/3f3f/UfdcP1dyrBke6HCA0/vcV6bfTpezLpB9ujnQ1bTp16pQOHjyonJwcJSUlRbqcqORbZ+SVV16JdCkxo6P7qqs/v2kZQdild7QKKxCrYnVqLxAFCCMIO9/+NIwZQVxhzAgQNGbTIOzSk30tI4QRxBHGjMSFdevWRbqEcxItIwi7Xr4BrHTTIJ7YmvvKY21qLxAFCCMIu9OzaWgZQRyxNe/aGmuLngFRgDCCsKObBnEphlZgjYFJlIghobifCCMIu16pp7tp+KaIuOFfgTV6ux99S4XX1dVFuBLEE9/9dOZS9GYwgBVh52sZaWwydMLtUQ8HtyHiQAxM7bVarUpPT/dvnJaSkhLSvVtwbjEMQ3V1daqqqlJ6erqsVmvQr8VPAYRdst0qhy1B9Y1N+vKEmzCC+OALI0aT5GmUrNF5X/u2r/cFEuBspaen+++rYEXnvxbEvfSURH1eW6+akw3K6vx0IPr5xoxI3tYRa+tt2qOBxWJRv3791KdPHzU0MG4LZycxMfGsWkR8CCOIiF4pdn1eW68vmd6LeGFrEUaieNyIj9VqDckPESAUGMCKiHAm+wax8psZ4kSCVUpo/v0uiseNANGIMIKISGfhM8Qj38JnMTC9F4gmQYWRkpIS/+58eXl52r59e7vnzpgxQxaLpdVjxIgRQReN2NcrhbVGEIeszQufxUA3DRBNTIeRDRs2qLCwUIsXL1Z5ebkmTJigSZMmqaKios3zH3/8cblcLv+jsrJS5513nv793//9rItH7GIVVsSlGJjeC0Qj02Fk+fLlmjlzpmbNmqXhw4dr5cqVysrK0qpVq9o83+l0qm/fvv7H7t279eWXX+qHP/zhWReP2OVrGWEAK+IKO/cCQTEVRtxut8rKylRQUBBwvKCgQDt27OjSa6xZs0bXXnutsrOz2z2nvr5etbW1AQ/El/TmAaw1dNMgnrBzLxAUU2GkurpaHo9HmZmZAcczMzN15MiRTq93uVx6/fXXNWvWrA7PKy4ultPp9D+ysliJIt6k0zKCeORfEp4BrIAZQQ1gPXP5YMMwurSk8Lp165Senq6bb765w/MWLVqkmpoa/6OysjKYMhHF0hkzgnhki53N8oBoYmrRs4yMDFmt1latIFVVVa1aS85kGIbWrl2rqVOnym63d3iuw+GQw+Ho8BzENmbTIC4xtRcIiqmWEbvdrry8PJWWlgYcLy0t1fjx4zu8duvWrfr44481c+ZM81Ui7rRcZ6SpiZ17ESd8U3sJI4ApppeDLyoq0tSpUzVmzBjl5+dr9erVqqio0OzZsyV5u1gOHTqk9evXB1y3Zs0ajR07Vrm5uaGpHDHNtwJrkyF95W5UWlLwW08DUYMxI0BQTIeRyZMn6+jRo1q6dKlcLpdyc3O1efNm/+wYl8vVas2Rmpoabdy4UY8//nhoqkbMS0q0KjnRqpMNHh070UAYQXxgai8QlKA2ypszZ47mzJnT5t+tW7eu1TGn06m6urpg3gpxLD0lUSdrPDp20q2BSol0OcDZY2ovEBT2pkHEnJ7eyyBWxAm6aYCgEEYQMenJbJaHOMPUXiAohBFETK9UXxihZQRxgjACBIUwgohxJrPWCOKMlTACBIMwgojp1bzWCEvCI24wZgQICmEEEeNb+KyGJeERL5jaCwSFMIKISfd30/CNG3GCqb1AUAgjiJh0fzcNLSOIE/5uGgI2YAZhBBHjW2eEbhrEDRstI0AwCCOIGAawIu4wtRcICmEEEeNsMYCVnXsRF5jaCwSFMIKI8Q1gNQyp9hRdNYgDtiTvf5naC5hCGEHE2G0JSrVbJbHwGeKEzRuwaRkBzCGMIKJ8g1iPMYgV8YBuGiAohBFEVDqDWBFPmNoLBIUwgojyr8JKNw3iAVN7gaAQRhBRvm4aWkYQF1gOHggKYQQRlZ7sbRlhACviAsvBA0EhjCCieqWwPw3iiG9qb1OD1NQU2VqAGEIYQUT5xowwmwZxwTe1V2KtEcAEwggi6vSYEcII4oCvm0Ziei9gAmEEEeUbM1JDNw3igTVRksX7Z6b3Al1GGEFE0U2DuGKxML0XCAJhBBHl76Y5wW+RiBNM7wVMI4wgonwtI7WnGuVh517EA6b3AqYRRhBRvjEjklRDVw3iATv3AqYRRhBRNmuCejpsklhrBHGCnXsB0wgjiLj0VN9mebSMIA74WkYII0CXEUYQcenJ3t8ka07SMoI4YG1uGWFqL9BlhBFEnG8Q65cnaBlBHGBqL2BaUGGkpKREOTk5SkpKUl5enrZv397h+fX19Vq8eLGys7PlcDh04YUXau3atUEVjPjjm97LWiOIC0ztBUyzmb1gw4YNKiwsVElJiS677DI9/fTTmjRpkvbu3auBAwe2ec0tt9yizz//XGvWrNHgwYNVVVWlxsbGsy4e8YFVWBFXmNoLmGY6jCxfvlwzZ87UrFmzJEkrV67Um2++qVWrVqm4uLjV+W+88Ya2bt2qTz75ROedd54kadCgQWdXNeJKrxQGsCKO+FpGmNoLdJmpbhq3262ysjIVFBQEHC8oKNCOHTvavObVV1/VmDFj9Mgjj+iCCy7QRRddpAULFujkyZPtvk99fb1qa2sDHohfTrppEE/83TSEEaCrTLWMVFdXy+PxKDMzM+B4Zmamjhw50uY1n3zyid555x0lJSXp5ZdfVnV1tebMmaN//etf7Y4bKS4u1pIlS8yUhhjmaxlhnRHEBcIIYFpQA1gtFkvAc8MwWh3zaWpqksVi0YsvvqhLL71UN954o5YvX65169a12zqyaNEi1dTU+B+VlZXBlIkY4d8sj24axAMrYQQwy1TLSEZGhqxWa6tWkKqqqlatJT79+vXTBRdcIKfT6T82fPhwGYahf/7znxoyZEiraxwOhxwOh5nSEMP8m+XRMoJ4wJgRwDRTLSN2u115eXkqLS0NOF5aWqrx48e3ec1ll12mw4cP66uvvvIf279/vxISEjRgwIAgSka8OT2bhpYRxAGm9gKmme6mKSoq0jPPPKO1a9dq3759uvfee1VRUaHZs2dL8naxTJs2zX/+lClT1Lt3b/3whz/U3r17tW3bNt1333360Y9+pOTk5NB9JYhZvpaR4/WNavA0Rbga4CwxtRcwzfTU3smTJ+vo0aNaunSpXC6XcnNztXnzZmVnZ0uSXC6XKioq/Of36NFDpaWluvvuuzVmzBj17t1bt9xyix5++OHQfRWIac4zdu7N6EEXHWIY3TSAaabDiCTNmTNHc+bMafPv1q1b1+rYsGHDWnXtAD7WBIvSkmyqPdWoY3WEEcQ4ZtMAprE3DaJCr9TmtUYYxIpYRxgBTCOMICr4BrEyvRcxj6m9gGmEEUQFpvcibtiSvP9lzAjQZYQRRAXfwmc1LAmPWGfzBmum9gJdRxhBVPB109AygpjH1F7ANMIIooKvm4YxI4h5/qm9BGugqwgjiAr+/WnopkGss9EyAphFGEFU6JXC1F7ECZaDB0wjjCAqONm5F/GCMSOAaYQRRIVejBlBvGBqL2AaYQRR4fSiZzRtI8b5p/YSRoCuIowgKvhaRk64PXI3snMvYljLFVgNI7K1ADGCMIKo0DPJJovF++djJ2kdQQzzDWCVITU1RrQUIFYQRhAVEhIscjZ31dQwbgSxzNZi12kGsQJdQhhB1Ojl35+GMIIYZm0ZRmjlA7qCMIKo4WQQK+JBQoKU4L2XaRkBuoYwgqjRi7VGEC+Y3guYQhhB1PDvT8MAVsQ6pvcCphBGEDV8+9MwZgQxr+X0XgCdIowgaqQnswor4gQ79wKmEEYQNXqlMoAVcYKdewFTCCOIGqdn09AyghjHzr2AKYQRRI3TA1gJI4hx7NwLmEIYQdQ4PbWX3yYR4/xjRhjACnQFYQRRgwGsiBs2ZtMAZhBGEDXSmwewnmzw6FSDJ8LVAGfBt+gZYQToEsIIokZPh03WBO/WvTWMG0EsszYvesbUXqBLCCOIGhaLRenJvoXP+CaOGMbUXsAUwgiiipP9aRAPmNoLmEIYQVRJZ+dexAOm9gKmEEYQVXqlMKMGcYCpvYApQYWRkpIS5eTkKCkpSXl5edq+fXu7527ZskUWi6XV48MPPwy6aMQvfzcNA1gRy5jaC5hiOoxs2LBBhYWFWrx4scrLyzVhwgRNmjRJFRUVHV730UcfyeVy+R9DhgwJumjEL1/LCANYEdMII4ApNrMXLF++XDNnztSsWbMkSStXrtSbb76pVatWqbi4uN3r+vTpo/T09KALxbnBN2bkt7v/qT9/XB3hagBzejhsevjmXA22EkYAM0yFEbfbrbKyMi1cuDDgeEFBgXbs2NHhtaNGjdKpU6d08cUX66c//amuuuqqds+tr69Xff3pf8S1tbVmykQMG5LZU5L0rxNu/esErSOIPa/uOawiJ2NGADNMhZHq6mp5PB5lZmYGHM/MzNSRI0favKZfv35avXq18vLyVF9fr+eff17XXHONtmzZoiuuuKLNa4qLi7VkyRIzpSFOXD8iU//f3MvopkHM+W3ZP/XaBy59Ve9hai9gkuluGsm7OFVLhmG0OuYzdOhQDR061P88Pz9flZWVWrZsWbthZNGiRSoqKvI/r62tVVZWVjClIsZYLBZdkpUe6TIA0z74Z41ek0snGxqZ2guYZGoAa0ZGhqxWa6tWkKqqqlatJR0ZN26cDhw40O7fOxwOpaWlBTwAIJql2K2SpDp3i5YRloMHusRUGLHb7crLy1NpaWnA8dLSUo0fP77Lr1NeXq5+/fqZeWsAiGopdm9D84mAbhpaRoCuMN1NU1RUpKlTp2rMmDHKz8/X6tWrVVFRodmzZ0vydrEcOnRI69evl+SdbTNo0CCNGDFCbrdbL7zwgjZu3KiNGzeG9isBgAjytYycbGhkai9gkukwMnnyZB09elRLly6Vy+VSbm6uNm/erOzsbEmSy+UKWHPE7XZrwYIFOnTokJKTkzVixAi99tpruvHGG0P3VQBAhCW37KZhai9gisUwDCPSRXSmtrZWTqdTNTU1jB8BEJXeOVCt/7PmXQ3r21Nv/CBZWnOt1GuQdM9fI10aEDFd/fnN3jQAEAK+lpET7kbJ5l1JmKm9QNcQRgAgBPxjRgK6aRjACnQFYQQAQoCpvUDwCCMAEAK+qb11bo+aEnzdNLSMAF1BGAGAEPC1jEjSKXk3fFRTo9TkiVBFQOwgjABACCQnng4jdU2n/8z0XqBzhBEACIGEBIs/kNR5Ek//BTv3Ap0ijABAiPgHsXokWZq/vdIyAnSKMAIAIcIqrEBwCCMAECKpvhk19UzvBcwgjABAiJxuGWlk517ABMIIAITI6Z17W7SMsCQ80CnCCACEiG/hsxP1LAkPmEEYAYAQSQnopknyHmRqL9ApwggAhEjAZnn+nXsJI0BnCCMAECL+bhqm9gKmEEYAIEROt4w0MrUXMIEwAgAhErDoGVN7gS4jjABAiKT6wkjA1F66aYDOEEYAIERS/CuwNjJmBDCBMAIAIdJmNw1Te4FOEUYAIETaXoGVMAJ0hjACACFyegXWFoueEUaAThFGACBEAhY9szYvesbUXqBThBEACJGUNmfTMLUX6AxhBABCJMXhm03Drr2AGYQRAAiRlERvy4jb0yRPgm9vGlpGgM4QRgAgRHxTeyXJbUn0/oGpvUCnCCMAECIOW4KsCRZJkttoDiPMpgE6RRgBgBCxWCz+rppThBGgy4IKIyUlJcrJyVFSUpLy8vK0ffv2Ll335z//WTabTd/4xjeCeVsAiHq+rpp6wzuYlTACdM50GNmwYYMKCwu1ePFilZeXa8KECZo0aZIqKio6vK6mpkbTpk3TNddcE3SxABDtUptn1Jz0hRHGjACdMh1Gli9frpkzZ2rWrFkaPny4Vq5cqaysLK1atarD6+68805NmTJF+fn5QRcLANEuubmb5mSTr2WEqb1AZ0yFEbfbrbKyMhUUFAQcLygo0I4dO9q97tlnn9U//vEPPfjgg116n/r6etXW1gY8ACAW+BY+O+UPI0ztBTpjKoxUV1fL4/EoMzMz4HhmZqaOHDnS5jUHDhzQwoUL9eKLL8pms3XpfYqLi+V0Ov2PrKwsM2UCQMT4Fj474QsjLAcPdCqoAawWiyXguWEYrY5Jksfj0ZQpU7RkyRJddNFFXX79RYsWqaamxv+orKwMpkwACDvfbJo6T/OaI7SMAJ3qWlNFs4yMDFmt1latIFVVVa1aSyTp+PHj2r17t8rLyzVv3jxJUlNTkwzDkM1m01tvvaWrr7661XUOh0MOh8NMaQAQFXzdNF95GDMCdJWplhG73a68vDyVlpYGHC8tLdX48eNbnZ+Wlqa//e1v2rNnj/8xe/ZsDR06VHv27NHYsWPPrnoAiDIpDm8YOUHLCNBlplpGJKmoqEhTp07VmDFjlJ+fr9WrV6uiokKzZ8+W5O1iOXTokNavX6+EhATl5uYGXN+nTx8lJSW1Og4A8SDF7v22eryx+Xc9T71kGFIbXdkAvEyHkcmTJ+vo0aNaunSpXC6XcnNztXnzZmVnZ0uSXC5Xp2uOAEC88k3tPd54ep8aeRokmz1CFQHRz2IYhhHpIjpTW1srp9OpmpoapaWlRbocAGjX01v/oeLXP9Qtl2TokY+al0FYWCkl8b0L556u/vxmbxoACCHf1N6ahhbfXpneC3SIMAIAIeSf2tvQJFmbu2YYxAp0iDACACHkm9p70u2RbEneg2yWB3SIMAIAIeRfgdXtadEyQhgBOkIYAYAQOt0y0ni6ZYSde4EOEUYAIIR8U3vr3J7T03lpGQE6RBgBgBBKbe6mqXN7JGvzthaEEaBDhBEACCFfN02du1GGrTmMMLUX6BBhBABCKLk5jDQZksHUXqBLCCMAEEK+dUYkyZNANw3QFYQRAAghmzVBdpv3W2ujJdF7kDACdIgwAgAh5hs34klo7qZhai/QIcIIAIRYqt07o6bBwtReoCsIIwAQYr5BrA3yhhLCCNAxwggAhJivm8btaxlhai/QIcIIAISYbxVWt3wDWJnaC3SEMAIAIeZbhbXeoJsG6ArCCACEmG/MSL3B1F6gKwgjABBivoXPTvnCCFN7gQ4RRgAgxHzdNCeN5tVYaRkBOkQYAYAQ83XTnGyimwboCsIIAISYr5vmZBMtI0BXEEYAIMRSmrtpTniaZ9MwZgToEGEEAELMt+jZCX/LCIueAR0hjABAiPnDSKMvjLDoGdARwggAhFhK80Z5x+mmAbqEMAIAIeZrGfmqsflbLANYgQ4RRgAgxHxTe483MpsG6ArCCACEWGpzN01tAy0jQFcQRgAgxHzdNP4wwpgRoEOEEQAIMV83TW0jU3uBrggqjJSUlCgnJ0dJSUnKy8vT9u3b2z33nXfe0WWXXabevXsrOTlZw4YN04oVK4IuGACina+bxu3ftZepvUBHbGYv2LBhgwoLC1VSUqLLLrtMTz/9tCZNmqS9e/dq4MCBrc5PTU3VvHnzNHLkSKWmpuqdd97RnXfeqdTUVN1xxx0h+SIAIJokJSbIYpHqfWHE8EieRslq+lsucE6wGIZhmLlg7NixGj16tFatWuU/Nnz4cN18880qLi7u0mt8//vfV2pqqp5//vkunV9bWyun06mamhqlpaWZKRcAIuLiB96Q4T6hfUk/8h64/7BkT41sUUCYdfXnt6luGrfbrbKyMhUUFAQcLygo0I4dO7r0GuXl5dqxY4cmTpzY7jn19fWqra0NeABALEmxW+VW4ukDzKgB2mUqjFRXV8vj8SgzMzPgeGZmpo4cOdLhtQMGDJDD4dCYMWM0d+5czZo1q91zi4uL5XQ6/Y+srCwzZQJAxKXYbfLIKsPCWiNAZ4IawGqxWAKeG4bR6tiZtm/frt27d+upp57SypUr9dJLL7V77qJFi1RTU+N/VFZWBlMmAESMb3pvk9XhPcD0XqBdpkZTZWRkyGq1tmoFqaqqatVacqacnBxJ0te//nV9/vnneuihh3Trrbe2ea7D4ZDD4TBTGgBEFd/0Xk+CXVbVMb0X6ICplhG73a68vDyVlpYGHC8tLdX48eO7/DqGYai+nt8SAMQv3/Rej4XpvUBnTM8zKyoq0tSpUzVmzBjl5+dr9erVqqio0OzZsyV5u1gOHTqk9evXS5KefPJJDRw4UMOGDZPkXXdk2bJluvvuu0P4ZQBAdPG1jDQm2L0HPLSMAO0xHUYmT56so0ePaunSpXK5XMrNzdXmzZuVnZ0tSXK5XKqoqPCf39TUpEWLFungwYOy2Wy68MIL9V//9V+68847Q/dVAECU8Y0Z8ViawwgtI0C7TK8zEgmsMwIg1iza9De99F6F3uv9kPqc2C/9n03S4GsiXRYQVt2yzggAoGt8LSMNvrVGmNoLtIswAgDdwBdG3L5uGqb2Au0ijABAN0jxb5bXPDSPlhGgXYQRAOgGvpaRehFGgM4QRgCgG/im9p7y7dzL1F6gXYQRAOgGvkXPTjX5WkaY2gu0hzACAN3A101zkjEjQKcIIwDQDXzdNCebCCNAZwgjANANfN00JzzNYYSpvUC7CCMA0A18LSN1Td7/0jICtI8wAgDdwDdmpM5DGAE6QxgBgG7gDyNNTO0FOkMYAYBu4F+BVUztBTpDGAGAbmC3JciWYFG9mvemoZsGaBdhBAC6SbLd2qJlhDACtIcwAgDdJNVuU71/OXjCCNAewggAdJMUu1VuNYcRWkaAdhFGAKCbJNutqieMAJ0ijABAN0m12wgjQBcQRgCgmyTbrXIbLAcPdIYwAgDdJCWgm4ZFz4D2EEYAoJuk2G0tBrCy6BnQHsIIAHSTgJYRloMH2kUYAYBukmK3ym3QMgJ0hjACAN0kpeVsGo9bMozIFgREKcIIAHSTlJbLwUtM7wXaQRgBgG6S3HIFVonpvUA7CCMA0E1SHWe2jDCIFWgLYQQAuklyok2Shem9QCcIIwDQTVLsVkmSW3bvAab3Am0KKoyUlJQoJydHSUlJysvL0/bt29s9d9OmTbruuut0/vnnKy0tTfn5+XrzzTeDLhgAYsXpMNLcVUPLCNAm02Fkw4YNKiws1OLFi1VeXq4JEyZo0qRJqqioaPP8bdu26brrrtPmzZtVVlamq666SjfddJPKy8vPungAiGYpdm8IYbM8oGMWwzA38X3s2LEaPXq0Vq1a5T82fPhw3XzzzSouLu7Sa4wYMUKTJ0/WAw880KXza2tr5XQ6VVNTo7S0NDPlAkDEfFp9Qlcu26Itjh9rkMUl/fANKTs/0mUBYdPVn9+mWkbcbrfKyspUUFAQcLygoEA7duzo0ms0NTXp+PHjOu+889o9p76+XrW1tQEPAIg1vm6aU+zcC3TIVBiprq6Wx+NRZmZmwPHMzEwdOXKkS6/x2GOP6cSJE7rlllvaPae4uFhOp9P/yMrKMlMmAESFFMeZ3TQMYAXaEtQAVovFEvDcMIxWx9ry0ksv6aGHHtKGDRvUp0+fds9btGiRampq/I/KyspgygSAiEpOZAAr0BW2zk85LSMjQ1artVUrSFVVVavWkjNt2LBBM2fO1G9/+1tde+21HZ7rcDjkcDjMlAYAUceaYJHDlqB6g517gY6Yahmx2+3Ky8tTaWlpwPHS0lKNHz++3eteeuklzZgxQ7/5zW/0rW99K7hKASAGpTpsLHoGdMJUy4gkFRUVaerUqRozZozy8/O1evVqVVRUaPbs2ZK8XSyHDh3S+vXrJXmDyLRp0/T4449r3Lhx/laV5ORkOZ3OEH4pABB9khOtqncztRfoiOkwMnnyZB09elRLly6Vy+VSbm6uNm/erOzsbEmSy+UKWHPk6aefVmNjo+bOnau5c+f6j0+fPl3r1q07+68AAKJYit0q9wnCCNAR02FEkubMmaM5c+a0+XdnBowtW7YE8xYAEBdSHLYWY0YII0Bb2JsGALpRSmKLnXtpGQHaRBgBgG6UYre2GMBKGAHaQhgBgG6U4rCdXvSMqb1AmwgjANCNvN00TO0FOkIYAYBulGy3nh7ASjcN0CbCCAB0o1SHVfUMYAU6RBgBgG6UYrepXnbvE6b2Am0ijABAN0pmai/QKcIIAHSjFMaMAJ0ijABAN0ppuVEeU3uBNhFGAKAbBa7AytReoC2EEQDoRil26+kBrI20jABtIYwAQDdKcdjkNmgZATpCGAGAbuRtGWHXXqAjhBEA6EbJiWyUB3SGMAIA3Si1xUZ5BmEEaBNhBAC6UYqdlhGgM4QRAOhGDlvC6am9jBkB2kQYAYBuZLFYZLMne/9sNEmexghXBEQfwggAdLOExKTTT5jeC7RCGAGAbpZod5x+wpLwQCuEEQDoZkkOhxoMq/cJLSNAK4QRAOhmAQufMaMGaIUwAgDdzDu917ckPGEEOBNhBAC6WcAqrEzvBVohjABAN0t12FRv+LppGMAKnIkwAgDdLDlgFVYGsAJnIowAQDdLSWTnXqAjhBEA6GYpDhsDWIEOEEYAoJul2K2qN+zeJ4QRoBXCCAB0M6b2Ah0LKoyUlJQoJydHSUlJysvL0/bt29s91+VyacqUKRo6dKgSEhJUWFgYbK0AEJNS7DbGjAAdMB1GNmzYoMLCQi1evFjl5eWaMGGCJk2apIqKijbPr6+v1/nnn6/FixfrkksuOeuCASDWpATMpmFqL3Am02Fk+fLlmjlzpmbNmqXhw4dr5cqVysrK0qpVq9o8f9CgQXr88cc1bdo0OZ3Osy4YAGJNst2qen83DVN7gTOZCiNut1tlZWUqKCgIOF5QUKAdO3aErKj6+nrV1tYGPAAgVqXaWyx6RjcN0IqpMFJdXS2Px6PMzMyA45mZmTpy5EjIiiouLpbT6fQ/srKyQvbaABBugd00hBHgTEENYLVYLAHPDcNodexsLFq0SDU1Nf5HZWVlyF4bAMItmV17gQ7ZzJyckZEhq9XaqhWkqqqqVWvJ2XA4HHI4HCF7PQCIpFS7zd8yYjSeUuh+dQPig6mWEbvdrry8PJWWlgYcLy0t1fjx40NaGADEi2S71T9mpKmBlhHgTKZaRiSpqKhIU6dO1ZgxY5Sfn6/Vq1eroqJCs2fPluTtYjl06JDWr1/vv2bPnj2SpK+++kpffPGF9uzZI7vdrosvvjg0XwUARLGWi5553CdljXA9QLQxHUYmT56so0ePaunSpXK5XMrNzdXmzZuVnZ0tybvI2ZlrjowaNcr/57KyMv3mN79Rdna2Pv3007OrHgBiQKI1QZ4E73LwjQ31ske4HiDamA4jkjRnzhzNmTOnzb9bt25dq2OGYQTzNgAQNwyrdxxcUwPrjABnYm8aAAgDi40wArSHMAIAYWA0hxGD5eCBVggjABAG1sQk7x9oGQFaIYwAQDjYvGHEYDl4oBXCCACEgdXu7aaxsAIr0AphBADCwJaYLEmyeBgzApyJMAIAYeBrGUloIowAZyKMAEAY2OzeMSMJjBkBWiGMAEAYJDpSJElWWkaAVggjABAGdoe3ZcRqEEaAMxFGACAMEh3eAaw2o1FqaopwNUB0IYwAQBg4klJOP2HcCBCAMAIAYeBISj79hLVGgACEEQAIgySHQ02GxfuEMAIEIIwAQBikOhLlls37hG4aIABhBADCINluVb0SvU/YuRcIQBgBgDBIsVvl9ocRdu4FWiKMAEAYpNptp1tG6KYBAhBGACAMku1W1RveMNLkpmUEaIkwAgBh0LKbxu0+GeFqgOhCGAGAMEhOtKq+eTZN/SnCCNASYQQAwiAhwaJGi12S5CaMAAEIIwAQJr4w0kA3DRCAMAIAYeJJ8I4ZaahnACvQEmEEAMKkKcEhiTACnIkwAgBh0mT1dtM00k0DBCCMAECYNFm9LSNNDbSMAC0RRgAgXJrDiIdFz4AAhBEACBdbcxihZQQIQBgBgHCxeceMGIQRIEBQYaSkpEQ5OTlKSkpSXl6etm/f3uH5W7duVV5enpKSkvS1r31NTz31VFDFAkAsS7AlSZKMRneEKwGii+kwsmHDBhUWFmrx4sUqLy/XhAkTNGnSJFVUVLR5/sGDB3XjjTdqwoQJKi8v1/3336/58+dr48aNZ108AMQSS6I3jKiRXXuBlkyHkeXLl2vmzJmaNWuWhg8frpUrVyorK0urVq1q8/ynnnpKAwcO1MqVKzV8+HDNmjVLP/rRj7Rs2bKzLh4AYklConfMiDx00wAt2cyc7Ha7VVZWpoULFwYcLygo0I4dO9q8ZufOnSooKAg4dv3112vNmjVqaGhQYmJiq2vq6+tVX3/6N4fa2lozZQJAVLI2t4z0qf1f7Sq5PcLVAIEyLpuuwZdcHpH3NhVGqqur5fF4lJmZGXA8MzNTR44cafOaI0eOtHl+Y2Ojqqur1a9fv1bXFBcXa8mSJWZKA4CoZ087X5I0wHBpQNX/jXA1QKDd/7xUioUw4mOxWAKeG4bR6lhn57d13GfRokUqKiryP6+trVVWVlYwpQJA1Mi9+j+069hhGSe+iHQpQCuZ2SMj9t6mwkhGRoasVmurVpCqqqpWrR8+ffv2bfN8m82m3r17t3mNw+GQw+EwUxoARD1HUorGTflppMsAoo6pAax2u115eXkqLS0NOF5aWqrx48e3eU1+fn6r89966y2NGTOmzfEiAADg3GJ6Nk1RUZGeeeYZrV27Vvv27dO9996riooKzZ49W5K3i2XatGn+82fPnq3PPvtMRUVF2rdvn9auXas1a9ZowYIFofsqAABAzDI9ZmTy5Mk6evSoli5dKpfLpdzcXG3evFnZ2dmSJJfLFbDmSE5OjjZv3qx7771XTz75pPr3769f/epX+sEPfhC6rwIAAMQsi+EbTRrFamtr5XQ6VVNTo7S0tEiXAwAAuqCrP7/ZmwYAAEQUYQQAAEQUYQQAAEQUYQQAAEQUYQQAAEQUYQQAAEQUYQQAAEQUYQQAAEQUYQQAAESU6eXgI8G3SGxtbW2EKwEAAF3l+7nd2WLvMRFGjh8/LknKysqKcCUAAMCs48ePy+l0tvv3MbE3TVNTkw4fPqyePXvKYrGE7HVra2uVlZWlyspK9rwJAz7v8OLzDi8+7/Di8w6/YD5zwzB0/Phx9e/fXwkJ7Y8MiYmWkYSEBA0YMKDbXj8tLY2bOYz4vMOLzzu8+LzDi887/Mx+5h21iPgwgBUAAEQUYQQAAETUOR1GHA6HHnzwQTkcjkiXck7g8w4vPu/w4vMOLz7v8OvOzzwmBrACAID4dU63jAAAgMgjjAAAgIgijAAAgIgijAAAgIg658LIl19+qalTp8rpdMrpdGrq1Kk6duxYh9fMmDFDFosl4DFu3LjwFBxjSkpKlJOTo6SkJOXl5Wn79u0dnr9161bl5eUpKSlJX/va1/TUU0+FqdL4YObz3rJlS6v72GKx6MMPPwxjxbFr27Ztuummm9S/f39ZLBa98sornV7D/R08s58393fwiouL9c1vflM9e/ZUnz59dPPNN+ujjz7q9LpQ3t/nXBiZMmWK9uzZozfeeENvvPGG9uzZo6lTp3Z63Q033CCXy+V/bN68OQzVxpYNGzaosLBQixcvVnl5uSZMmKBJkyapoqKizfMPHjyoG2+8URMmTFB5ebnuv/9+zZ8/Xxs3bgxz5bHJ7Oft89FHHwXcy0OGDAlTxbHtxIkTuuSSS/TrX/+6S+dzf58ds5+3D/e3eVu3btXcuXO1a9culZaWqrGxUQUFBTpx4kS714T8/jbOIXv37jUkGbt27fIf27lzpyHJ+PDDD9u9bvr06cZ3v/vdMFQY2y699FJj9uzZAceGDRtmLFy4sM3zf/KTnxjDhg0LOHbnnXca48aN67Ya44nZz/vtt982JBlffvllGKqLb5KMl19+ucNzuL9DpyufN/d36FRVVRmSjK1bt7Z7Tqjv73OqZWTnzp1yOp0aO3as/9i4cePkdDq1Y8eODq/dsmWL+vTpo4suuki33367qqqqurvcmOJ2u1VWVqaCgoKA4wUFBe1+tjt37mx1/vXXX6/du3eroaGh22qNB8F83j6jRo1Sv379dM011+jtt9/uzjLPadzfkcH9ffZqamokSeedd16754T6/j6nwsiRI0fUp0+fVsf79OmjI0eOtHvdpEmT9OKLL+pPf/qTHnvsMb3//vu6+uqrVV9f353lxpTq6mp5PB5lZmYGHM/MzGz3sz1y5Eib5zc2Nqq6urrbao0HwXze/fr10+rVq7Vx40Zt2rRJQ4cO1TXXXKNt27aFo+RzDvd3eHF/h4ZhGCoqKtLll1+u3Nzcds8L9f0dE7v2duahhx7SkiVLOjzn/ffflyRZLJZWf2cYRpvHfSZPnuz/c25ursaMGaPs7Gy99tpr+v73vx9k1fHpzM+xs8+2rfPbOo62mfm8hw4dqqFDh/qf5+fnq7KyUsuWLdMVV1zRrXWeq7i/w4f7OzTmzZunDz74QO+8806n54by/o6LMDJv3jz9x3/8R4fnDBo0SB988IE+//zzVn/3xRdftEp4HenXr5+ys7N14MAB07XGq4yMDFmt1la/lVdVVbX72fbt27fN8202m3r37t1ttcaDYD7vtowbN04vvPBCqMuDuL+jAfe3OXfffbdeffVVbdu2TQMGDOjw3FDf33ERRjIyMpSRkdHpefn5+aqpqdF7772nSy+9VJL07rvvqqamRuPHj+/y+x09elSVlZXq169f0DXHG7vdrry8PJWWlup73/ue/3hpaam++93vtnlNfn6+/t//+38Bx9566y2NGTNGiYmJ3VpvrAvm825LeXk593E34f6OPO7vrjEMQ3fffbdefvllbdmyRTk5OZ1eE/L7O6hhrzHshhtuMEaOHGns3LnT2Llzp/H1r3/d+Pa3vx1wztChQ41NmzYZhmEYx48fN3784x8bO3bsMA4ePGi8/fbbRn5+vnHBBRcYtbW1kfgSotb//M//GImJicaaNWuMvXv3GoWFhUZqaqrx6aefGoZhGAsXLjSmTp3qP/+TTz4xUlJSjHvvvdfYu3evsWbNGiMxMdH43e9+F6kvIaaY/bxXrFhhvPzyy8b+/fuNv//978bChQsNScbGjRsj9SXElOPHjxvl5eVGeXm5IclYvny5UV5ebnz22WeGYXB/h5rZz5v7O3h33XWX4XQ6jS1bthgul8v/qKur85/T3ff3ORdGjh49atx2221Gz549jZ49exq33XZbq6lgkoxnn33WMAzDqKurMwoKCozzzz/fSExMNAYOHGhMnz7dqKioCH/xMeDJJ580srOzDbvdbowePTpgatj06dONiRMnBpy/ZcsWY9SoUYbdbjcGDRpkrFq1KswVxzYzn/cvf/lL48ILLzSSkpKMXr16GZdffrnx2muvRaDq2OSbOnrmY/r06YZhcH+HmtnPm/s7eG19zi1/DhpG99/fluZCAAAAIuKcmtoLAACiD2EEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABEFGEEAABE1P8PKUeKoKiO7VcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(-0.5, 2, 0.05):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot(np.arange(-0.5, 2, 0.05),les_pretrained,  label='pretrained')\n",
    "plt.plot(np.arange(-0.5, 2, 0.05),   les_not_pretrained,   label='not pretrained')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/extractor.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
