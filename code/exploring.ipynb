{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont 36 eeg avec certains egge \"anormaux\" et d'autres \"normaux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data from https://www.kaggle.com/datasets/amananandrai/complete-eeg-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "durée = 60s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq = 516 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ce que je fais c'est que je découpe chaque eeg en petits patchs de 1000 points. La tache de classification sera de prendre un patch de 1000 points et de le classifier en malade / non malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set construct_files to True if you want to construct the files\n",
    "construct_files = False\n",
    "if construct_files : \n",
    "    np.random.seed(0)\n",
    "    counts = [str(i) for i in range(31)]\n",
    "    counts = ['0' + i if len(i) == 1 else i for i in counts]\n",
    "\n",
    "    for file_name in counts : \n",
    "        df = pd.read_csv('./../data/kaggle_2/s'+file_name+'.csv', header=None).transpose().to_numpy()\n",
    "        for i in range(31*4): \n",
    "            sample = pd.DataFrame(df[:, 250*i:250*i+1000]) # slicing of 250 \n",
    "            random_float = np.random.rand()\n",
    "            if random_float < 0.1:\n",
    "                sample.to_csv('./../data/test/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            elif random_float < 0.3 : \n",
    "                sample.to_csv('./../data/validation/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            else:\n",
    "                sample.to_csv('./../data/train/'+file_name+'_'+str(i)+'_'+'.csv', index=False, header=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, je définis un dataset pretraining. La tache de pretraining consiste à prendre deux patchs de longueur 1000 dans un même eeg et de dire s'ils sont à côté ou non. \n",
    "\n",
    "Ainsi, on découpe chaque eeg en patchs glissants de taille 1000 et glissant de 250 à chaque fois. Ca fait 31*4 - 4 = 120 patchs. __getitem__ renvoie soit un patch et son voisin de droite à 500 points, soit un patch et le patch situé à 15500 points de lui (on rapelle que les eeg font 31 000 points). En plus de cela, il renvoie les indices des deux patchs (pour la classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_pretraining(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data, n_files=36, n_samples_per_file=31*4, segment_length=1000, slide = 250):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_files = n_files\n",
    "        self.slide = slide\n",
    "        self.n_samples_per_file = n_samples_per_file\n",
    "        self.segment_length = segment_length\n",
    "        self.data = []\n",
    "        for file in range(self.n_files):\n",
    "            x = pd.read_csv(self.path_to_data + 's' + str(file).zfill(2) + '.csv', header=None).transpose().to_numpy()\n",
    "            self.data.append(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files * self.n_samples_per_file*2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = idx // ((31*4)*2)\n",
    "        sample = (idx % ((31*4)*2))\n",
    "        first = (sample % (31*4))*250\n",
    "        if first+1000 >= 31000:\n",
    "            first = 30000-1\n",
    "        if sample // (31*4) == 0:  # proches, second est une fenêtre proche de first\n",
    "            if first + 1500 > 31000:\n",
    "                second  = first  - 500\n",
    "            else : \n",
    "                second = first + 500\n",
    "        else: # éloignés, second est une fenêtre éloignée de first\n",
    "            assert sample // (31*4) == 1\n",
    "            second = first + 15500\n",
    "            if second + 1000 > 31000:\n",
    "                second = 15500\n",
    "        x1 = self.data[file][:, first: first+self.segment_length]  # Utilisation de la donnée préchargée\n",
    "        x2 = self.data[file][:, second: second+self.segment_length]\n",
    "        return torch.stack([torch.tensor(x1), torch.tensor(x2)]), torch.tensor([first, second])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, on définit le dataset pour la tache finale de classification. On renvoie un sous_eeg de 1000 points ainsi que le label auquel il est associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data # par example './../data/train/\n",
    "        self.X = os.listdir(self.path_to_data) # the list of the files in the train set \n",
    "        self.data=[]\n",
    "        self.labels=np.array([0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1])\n",
    "        for idx in range(len(self.X)):\n",
    "            x = pd.read_csv(self.path_to_data + self.X[idx], header=None).to_numpy()\n",
    "            self.data.append((x, self.labels[int(self.X[idx].split('_')[0])]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x , y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell to build the dataloaders. J'ai fait n'imp sur les dataloaders train, val et test donc ça prend un temps fou à charger; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n",
      "val finished\n",
      "test finished\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(Mydataset('./../data/train/'), batch_size=5, shuffle=True)\n",
    "print('train finished')\n",
    "dataloader_val = DataLoader(Mydataset('./../data/validation/'), batch_size=5, shuffle=True)\n",
    "print('val finished')\n",
    "dataloader_test = DataLoader(Mydataset('./../data/test/'), batch_size=5, shuffle=True)\n",
    "print('test finished')\n",
    "dataloader_pretraining = DataLoader(Dataset_pretraining('./../data/kaggle_2/'), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 19, 1000])\n",
      "torch.Size([1, 2])\n",
      "--------------------\n",
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_pretraining :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break\n",
    "print('--------------------')\n",
    "for batch in dataloader_train :\n",
    "  print(batch[0].shape)\n",
    "  print(batch[1].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est notre feature extractor, convolutionnel grosso modo comme ce qu'on a dans l'article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGFeatureExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(EEGFeatureExtractor, self).__init__()\n",
    "        # input [batch_size, 19, 1000]\n",
    "        self.conv1= nn.Conv1d(19, 32, 3, padding=1)\n",
    "        self.conv2= nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv3= nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.conv4= nn.Conv1d(6, 10, 3, padding=1)   \n",
    "        self.conv5 = nn.Conv1d(64, 15, 3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(1, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(150, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('au début', x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # print(1, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(2, x.shape)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # print(3, x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(4, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(5, x.shape)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        # print(6, x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(7, x.shape)\n",
    "        x = self.conv5(x)\n",
    "        # print(8, x.shape)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # print(9, x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print('a la fin', x.shape)\n",
    "        x = self.fc(x)\n",
    "        return self.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19, 1000])\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train :\n",
    "  x = batch[0]\n",
    "  print(x.shape)\n",
    "  model = EEGFeatureExtractor()\n",
    "  print(model(x.float()).shape)  \n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine le features extractor : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_sauvegarde = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grego\\miniconda3\\envs\\map588\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_extractor = False\n",
    "tau = 516 # 1 seconde\n",
    "model_name='extractor'\n",
    "if not os.path.exists('./models/'+model_name):\n",
    "    os.makedirs('./models/'+model_name)\n",
    "device = 'cpu'\n",
    "model = EEGFeatureExtractor()\n",
    "n_epochs=200\n",
    "loss = torch.nn.L1Loss()\n",
    "param_1 = torch.nn.Parameter(torch.ones(100, requires_grad=True))\n",
    "param_2 =  torch.nn.Parameter(torch.ones(1, requires_grad=True))\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': model.parameters()}, {'params': [param_1, param_2]}],\n",
    "    lr=0.1\n",
    ")\n",
    "model.to(device)\n",
    "loss_train=[]\n",
    "if train_extractor:\n",
    "    for epoch in (range(n_epochs)):\n",
    "        print('epoch', epoch)\n",
    "        losstrain=0\n",
    "        counttrain=0\n",
    "        lossval=0\n",
    "        countval=0\n",
    "        for batch_x,batch_y in dataloader_pretraining:\n",
    "            batch_x=batch_x[0].to(device)\n",
    "            batch_y = batch_y.long()\n",
    "            batch_y=batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            first_window = batch_x[0]\n",
    "            second_window = batch_x[1]\n",
    "            # print('the shape is', first_window.float().shape)\n",
    "            first_prediction = model(first_window.float().unsqueeze(0))\n",
    "            second_prediction = model(second_window.float().unsqueeze(0))\n",
    "            label_predicted = torch.dot(param_1, abs(first_prediction - second_prediction).squeeze()) + param_2\n",
    "            idx_1 = batch_y[0][0]\n",
    "            idx_2 = batch_y[0][1]\n",
    "            if (\n",
    "                \n",
    "                abs(idx_1- idx_2 ) < 1000 # close in time\n",
    "            ) : \n",
    "                y_pred = torch.tensor([-1]).to(device)\n",
    "            else:\n",
    "                y_pred = torch.tensor([1]).to(device) # 1 s'ils sont proches, -1 sinon\n",
    "            l=-torch.nn.functional.logsigmoid(y_pred * label_predicted)\n",
    "            # l=torch.log(1+torch.exp(-y_pred*label_predicted))\n",
    "            counttrain+=1\n",
    "            l.backward()\n",
    "            losstrain+=l\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "        loss_train.append(losstrain/counttrain)\n",
    "        \n",
    "    torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "\n",
    "\n",
    "    # saving the losses in txt files : \n",
    "    loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "\n",
    "\n",
    "\n",
    "    with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "        for elt in loss_list_train : \n",
    "            f.write(str(elt) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là hop le classifieur, qui est constitué d'un feature extractor puis d'une couche fully connected. Soit on entraine tout d'un coup soit on entraine séparément les deux parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.fc = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.fc(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La c'est les boucles d'entrainement qui sont aussi dans le fichier .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = torch.load('./models/extractor.pth')\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "model = EEGClassifier(pretrained)\n",
    "# loss for classification : \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "model_name = 'classifier_pretrained'\n",
    "loss_train=[]\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+model_name+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_pretrained = EEGFeatureExtractor()\n",
    "model = EEGClassifier(not_pretrained)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model_name = 'classifier_not_pretrained'\n",
    "loss_train=[]\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=200\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())\n",
    "for epoch in range(n_epochs):\n",
    "    print('epoch', epoch)\n",
    "    losstrain=0\n",
    "    counttrain=0\n",
    "    for batch_x,batch_y in dataloader_train:\n",
    "        batch_x=batch_x.to(device)\n",
    "        batch_y = batch_y.float()\n",
    "        batch_y=batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x.float())\n",
    "        l=loss(y_pred.squeeze(), batch_y)\n",
    "        counttrain+=1\n",
    "        l.backward()\n",
    "        losstrain+=l\n",
    "        optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch}, training loss = {losstrain/counttrain}')\n",
    "    loss_train.append(losstrain/counttrain)\n",
    "torch.save(model, chemin_vers_sauvegarde+'_final'+'.pth')\n",
    "loss_list_train = [loss_train[i].detach().cpu().numpy() for i in range(len(loss_train))]\n",
    "with open('./losses/loss_train_'+model_name+'.txt', 'w') as f :\n",
    "    for elt in loss_list_train : \n",
    "        f.write(str(elt) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière cellule pour l'évaluation finale !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score pretrained 0.8095238095238095\n",
      "F1 score not pretrained 0.7592137592137592\n"
     ]
    }
   ],
   "source": [
    "pretrained = torch.load('./models/classifier_pretrained_final.pth')\n",
    "not_pretrained = torch.load('./models/classifier_not_pretrained.pth')\n",
    "y_true =np.array( [])\n",
    "y_pred_pretrained = np.array( [])\n",
    "y_pred_not_pretrained = np.array( [])\n",
    "for batch_x, batch_y in dataloader_test:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_y = batch_y.to(device)\n",
    "    y_pretrained = pretrained(batch_x.float())\n",
    "    y_not_pretrained = not_pretrained(batch_x.float())\n",
    "    y_true=np.concatenate((y_true, batch_y.numpy()))\n",
    "    y_pretrained = y_pretrained.detach().numpy()\n",
    "    y_not_pretrained = y_not_pretrained.detach().numpy()\n",
    "    y_pred_pretrained=np.concatenate((y_pred_pretrained, y_pretrained.flatten()))\n",
    "    y_pred_not_pretrained=np.concatenate((y_pred_not_pretrained, y_not_pretrained.flatten()))\n",
    "\n",
    "y_pred_pretrained = (y_pred_pretrained > 0.5).astype(int)\n",
    "y_pred_not_pretrained = (y_pred_not_pretrained > 0.5).astype(int)\n",
    "print('F1 score pretrained', f1_score(y_true, y_pred_pretrained))\n",
    "print('F1 score not pretrained', f1_score(y_true, y_pred_not_pretrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "les_pretrained= []\n",
    "les_not_pretrained = []\n",
    "for threshold in np.arange(-0.5, 2, 0.05):\n",
    "    y_pred_pretrained_oui = (y_pred_pretrained > threshold).astype(int)\n",
    "    y_pred_not_pretrained_oui = (y_pred_not_pretrained > threshold).astype(int)\n",
    "    les_pretrained.append(f1_score(y_true, y_pred_pretrained_oui))\n",
    "    les_not_pretrained.append(f1_score(y_true, y_pred_not_pretrained_oui))\n",
    "plt.plot(np.arange(-0.5, 2, 0.05),  les_pretrained,  label='pretrained')\n",
    "plt.plot(np.arange(-0.5, 2, 0.05),   les_not_pretrained,   label='not pretrained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/extractor.pth')\n",
    "for batch_x, batch_y in dataloader_test : \n",
    "    # print(batch_x)\n",
    "    print(model(batch_x.float()))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map588",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
